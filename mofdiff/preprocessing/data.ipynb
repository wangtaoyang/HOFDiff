{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from openbabel import openbabel as ob\n",
    "import numpy as np\n",
    "from mofdiff.common.constants import COVALENT_RADII\n",
    "\n",
    "def has_no_overlapping_atoms(cif_path, threshold=0.85):\n",
    "    \"\"\"\n",
    "    判断给定的 CIF 文件中是否有重叠的原子。如果没有重叠原子则返回 True，否则返回 False。\n",
    "\n",
    "    :param cif_path: CIF 文件路径\n",
    "    :param threshold: 判定原子是否重叠的阈值，默认为 0.85\n",
    "    :return: 没有重叠原子返回 True，有重叠原子返回 False\n",
    "    \"\"\"\n",
    "    obConversion = ob.OBConversion()\n",
    "    obConversion.SetInFormat(\"cif\")\n",
    "    mol = ob.OBMol()\n",
    "\n",
    "    if not obConversion.ReadFile(mol, str(cif_path)):\n",
    "        print(f\"Failed to read {cif_path} file.\")\n",
    "        return False\n",
    "\n",
    "    fragments = mol.Separate()\n",
    "\n",
    "    for frag in fragments:\n",
    "        frag_mol = ob.OBMol(frag)\n",
    "        other_atoms = []\n",
    "\n",
    "        for atom in ob.OBMolAtomIter(frag_mol):\n",
    "            pos = np.array([atom.GetX(), atom.GetY(), atom.GetZ()])\n",
    "            e1 = atom.GetType()\n",
    "\n",
    "            for other_atom in other_atoms:\n",
    "                other_pos = np.array([other_atom.GetX(), other_atom.GetY(), other_atom.GetZ()])\n",
    "                e2 = other_atom.GetType()\n",
    "\n",
    "                # 去掉 e1 和 e2 的数字，只保留字母\n",
    "                e1 = ''.join([i for i in e1 if not i.isdigit()])\n",
    "                e2 = ''.join([i for i in e2 if not i.isdigit()])\n",
    "\n",
    "                try:\n",
    "                    min_threshold = min(COVALENT_RADII[e1], COVALENT_RADII[e2])\n",
    "                except KeyError as e:\n",
    "                    continue\n",
    "\n",
    "                if np.linalg.norm(pos - other_pos) < threshold * min_threshold:\n",
    "                    return False\n",
    "\n",
    "            other_atoms.append(atom)\n",
    "\n",
    "    return True\n",
    "\n",
    "def process_cif_file(args):\n",
    "    \"\"\"处理单个 CIF 文件，检查是否有重叠原子并复制。\"\"\"\n",
    "    cif_path, target_dir, threshold = args\n",
    "    if has_no_overlapping_atoms(cif_path, threshold):\n",
    "        target_path = target_dir / cif_path.name\n",
    "        shutil.copy(cif_path, target_path)\n",
    "        print(f\"Copied: {cif_path} -> {target_path}\")\n",
    "    else:\n",
    "        print(f\"Skipped: {cif_path}\")\n",
    "\n",
    "def main(source_dir, target_dir, threshold=0.85):\n",
    "    \"\"\"主函数，遍历源文件夹中的 CIF 文件并复制符合条件的文件。\"\"\"\n",
    "    source_dir = Path(source_dir)\n",
    "    target_dir = Path(target_dir)\n",
    "\n",
    "    # 创建目标文件夹\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 获取所有 CIF 文件路径\n",
    "    cif_files = list(source_dir.glob(\"**/*.cif\"))\n",
    "\n",
    "    # 准备并行处理参数\n",
    "    tasks = [(cif_file, target_dir, threshold) for cif_file in cif_files]\n",
    "\n",
    "    # 使用多进程加速\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        pool.map(process_cif_file, tasks)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    source_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/temp_all\"\n",
    "    target_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/temp_no_overlap\"\n",
    "    threshold_value = 0.9\n",
    "\n",
    "    main(source_directory, target_directory, threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "\n",
    "class HydrogenBondChecker:\n",
    "    def __init__(self, cifs_path):\n",
    "        self.cifs_path = cifs_path\n",
    "\n",
    "    def get_Hbond_lists(self, cif_id):\n",
    "        donors, hs, acceptors = [], [], []\n",
    "        lis_path = os.path.join(self.cifs_path, f\"{cif_id}.lis\")\n",
    "        if not os.path.exists(lis_path):\n",
    "            print(f\"No LIS file found for CIF ID {cif_id}.\")\n",
    "            return donors, hs, acceptors\n",
    "        with open(lis_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            print(\"cid\", cif_id)\n",
    "            print(\"content:\", content)\n",
    "            data_block_match = re.search(r\"(Nr Typ Res Donor.*?)(?=\\n[A-Z])\", content, re.DOTALL | re.MULTILINE)\n",
    "        if data_block_match:\n",
    "            data_block = data_block_match.group(0)\n",
    "            lines = data_block.splitlines()\n",
    "            for line in lines:\n",
    "                if \"?\" in line:\n",
    "                    continue\n",
    "                line = re.sub(r'Intra', ' ', line)\n",
    "                line = re.sub(r'\\d\\*', '1 ', line)\n",
    "                line = re.sub(r'_[a-z*]', ' ', line)\n",
    "                line = re.sub(r'_[0-9*]', ' ', line)\n",
    "                line = re.sub(r'_', ' ', line)\n",
    "                line = re.sub(r'>', ' ', line)\n",
    "                line = re.sub(r'<', ' ', line)\n",
    "                columns = line.split()\n",
    "                if len(columns) > 1 and (columns[0].isdigit() or columns[0].startswith('**')) and columns[1].isdigit():\n",
    "                    donor = re.search(r'[A-Za-z]+\\d+[A-Z]*$', columns[2])\n",
    "                    h = re.search(r'[A-Za-z]+\\d+[A-Z]*$', columns[3])\n",
    "                    acceptor = re.search(r'[A-Za-z]+\\d+[A-Z]*$', columns[4])\n",
    "                    if donor and not donor.group().startswith('C'):\n",
    "                        donors.append(donor.group())\n",
    "                        if h:\n",
    "                            hs.append(h.group())\n",
    "                        if acceptor:\n",
    "                            acceptors.append(acceptor.group())\n",
    "\n",
    "        return donors, hs, acceptors\n",
    "\n",
    "    @staticmethod\n",
    "    def read_cif_extract_block(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "        start = content.find('_atom_site_occupancy')\n",
    "        if start == -1:\n",
    "            return None, 0\n",
    "        data_block = content[start:].split('\\n')[1:]\n",
    "        return data_block, len(data_block)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_atom_labels(data_block):\n",
    "        atom_labels = []\n",
    "        for line in data_block:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            atom_labels.append(parts[1])\n",
    "        return atom_labels\n",
    "\n",
    "    @staticmethod\n",
    "    def classify_atoms(atom_labels, donors, hs, acceptors):\n",
    "        atom_classification = []\n",
    "        for label in atom_labels:\n",
    "            if label in donors:\n",
    "                atom_classification.append(1)\n",
    "            elif label in hs:\n",
    "                atom_classification.append(2)\n",
    "            elif label in acceptors:\n",
    "                atom_classification.append(3)\n",
    "            else:\n",
    "                atom_classification.append(0)\n",
    "        return atom_classification\n",
    "\n",
    "    def get_Hbond(self, cif_id):\n",
    "        donors, hs, acceptors = self.get_Hbond_lists(cif_id)\n",
    "        file_path = os.path.join(self.cifs_path, f\"{cif_id}.cif\")\n",
    "        data_block, _ = self.read_cif_extract_block(file_path)\n",
    "        if data_block:\n",
    "            atom_labels = self.extract_atom_labels(data_block)\n",
    "            atom_classification = self.classify_atoms(atom_labels, donors, hs, acceptors)\n",
    "            return torch.LongTensor(np.array(atom_classification, dtype=np.int8))\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def find_and_copy_cif_files(src_folder, dest_folder):\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    checker = HydrogenBondChecker(src_folder)\n",
    "    for file in os.listdir(src_folder):\n",
    "        if file.endswith(\".lis\"):\n",
    "            cif_id = os.path.splitext(file)[0]\n",
    "            hbond_tensor = checker.get_Hbond(cif_id)\n",
    "            if hbond_tensor is not None and torch.any(hbond_tensor == 1):  # 检查是否存在氢键\n",
    "                cif_path = os.path.join(src_folder, f\"{cif_id}.cif\")\n",
    "                if os.path.exists(cif_path):\n",
    "                    shutil.copy(cif_path, dest_folder)\n",
    "                    print(f\"Copied {cif_id}.cif to {dest_folder}\")\n",
    "                else:\n",
    "                    print(f\"No CIF file found for LIS ID {cif_id}.\")\n",
    "\n",
    "\n",
    "# 示例用法\n",
    "src_folder = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/temp_no_overlap\"  # 替换为实际的源文件夹路径\n",
    "dest_folder = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/temp_hbond\"  # 替换为实际的目标文件夹路径\n",
    "\n",
    "find_and_copy_cif_files(src_folder, dest_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from mofchecker import MOFChecker\n",
    "\n",
    "def check_mof_validity(cif_path):\n",
    "    \"\"\"\n",
    "    检查 MOF 的有效性。\n",
    "    参数:\n",
    "        cif_path (str): MOF 的 CIF 文件路径。\n",
    "    返回:\n",
    "        bool: 如果 MOF 有效返回 True，否则返回 False。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mofchecker = MOFChecker.from_cif(cif_path)\n",
    "        result = mofchecker.get_mof_descriptors()\n",
    "        # 根据指定条件判断 MOF 是否有效\n",
    "        is_valid = not result[\"has_atomic_overlaps\"] and \\\n",
    "                not result[\"has_lone_molecule\"] and \\\n",
    "                not result[\"has_overcoordinated_c\"] and \\\n",
    "                not result[\"has_overcoordinated_n\"] and \\\n",
    "                not result[\"has_overcoordinated_h\"] and \\\n",
    "                not result[\"has_undercoordinated_c\"] and \\\n",
    "                not result[\"has_undercoordinated_n\"] and \\\n",
    "                not result[\"has_metal\"] \n",
    "        return is_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking MOF {cif_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def process_mofs(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    遍历输入文件夹中的 CIF 文件，检查有效性，并将有效文件复制到目标文件夹。\n",
    "    参数:\n",
    "        input_dir (str): 输入文件夹路径，包含 CIF 文件。\n",
    "        output_dir (str): 输出文件夹路径，用于存储有效的 CIF 文件。\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cif_files = list(input_dir.glob(\"*.cif\"))\n",
    "\n",
    "    print(f\"Found {len(cif_files)} CIF files to process.\")\n",
    "    \n",
    "    valid_count = 0\n",
    "    for cif_file in cif_files:\n",
    "        print(f\"Checking {cif_file}...\")\n",
    "        if check_mof_validity(cif_file):\n",
    "            shutil.copy(cif_file, output_dir / cif_file.name)\n",
    "            print(f\"Copied valid CIF: {cif_file.name}\")\n",
    "            valid_count += 1\n",
    "        # else:\n",
    "            # print(f\"Invalid CIF: {cif_file.name}\")\n",
    "\n",
    "    print(f\"Processing complete. {valid_count} valid CIF files were copied to {output_dir}.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为实际路径\n",
    "    input_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/test_relax\"  # CIF 文件的源文件夹\n",
    "    output_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/hofchecker\"  # 用于存储有效 CIF 文件的目标文件夹\n",
    "\n",
    "    process_mofs(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from mofchecker import MOFChecker\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def check_mof_validity(cif_path):\n",
    "    \"\"\"\n",
    "    检查 MOF 的有效性。\n",
    "    参数:\n",
    "        cif_path (str): MOF 的 CIF 文件路径。\n",
    "    返回:\n",
    "        tuple: (cif_path, is_valid)，路径和有效性标识。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        mofchecker = MOFChecker.from_cif(cif_path)\n",
    "        result = mofchecker.get_mof_descriptors()\n",
    "        # 根据指定条件判断 HOF 是否有效\n",
    "        is_valid = not result[\"has_atomic_overlaps\"] and \\\n",
    "                   not result[\"has_metal\"]\n",
    "        return cif_path, is_valid\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking HOF {cif_path}: {e}\")\n",
    "        return cif_path, False\n",
    "\n",
    "\n",
    "def process_mofs(input_dir, output_dir, n_workers=4):\n",
    "    \"\"\"\n",
    "    遍历输入文件夹中的 CIF 文件，检查有效性，并将有效文件复制到目标文件夹。\n",
    "    参数:\n",
    "        input_dir (str): 输入文件夹路径，包含 CIF 文件。\n",
    "        output_dir (str): 输出文件夹路径，用于存储有效的 CIF 文件。\n",
    "        n_workers (int): 并行处理的进程数。\n",
    "    \"\"\"\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cif_files = list(input_dir.glob(\"*.cif\"))\n",
    "    print(f\"Found {len(cif_files)} CIF files to process.\")\n",
    "\n",
    "    valid_count = 0\n",
    "\n",
    "    # 使用 ProcessPoolExecutor 并行化处理\n",
    "    with ProcessPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # 用 tqdm 包裹文件列表，显示进度条\n",
    "        results = list(\n",
    "            tqdm(\n",
    "                executor.map(check_mof_validity, cif_files),\n",
    "                total=len(cif_files),\n",
    "                desc=\"Processing CIF files\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # 复制有效的文件到目标文件夹\n",
    "    for cif_path, is_valid in results:\n",
    "        if is_valid:\n",
    "            shutil.copy(cif_path, output_dir / cif_path.name)\n",
    "            valid_count += 1\n",
    "\n",
    "    print(f\"Processing complete. {valid_count} valid CIF files were copied to {output_dir}.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 替换为实际路径\n",
    "    input_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/test_relax\"  # CIF 文件的源文件夹\n",
    "    output_directory = \"/data/user2/wty/HOF/MOFDiff/mofdiff/data/mof_models/mof_models/bwdb_hoff/hofchecker\"  # 用于存储有效 CIF 文件的目标文件夹\n",
    "\n",
    "    # 调整 n_workers 的值以控制并行进程数\n",
    "    process_mofs(input_directory, output_directory, n_workers=100)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
